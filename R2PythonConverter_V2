import re
import datetime
import glob
import os

# -----------------------------
# Utility Functions
# -----------------------------
def to_snake_case(name: str) -> str:
    name = re.sub(r'([a-z0-9])\.([a-z0-9])', r'\1_\2', name)
    name = re.sub(r'([a-z])([A-Z])', r'\1_\2', name)
    return name.lower()

def preserve_strings(code: str):
    """
    Mask all string literals ("..." or '...') to placeholders __STR_n__
    so regex transforms don’t corrupt them.
    """
    strings = {}
    def replacer(m):
        key = f"__STR_{len(strings)}__"
        strings[key] = m.group(0)
        return key
    masked = re.sub(r'''("([^"\\]

|\\.)*")|('([^'\\]

|\\.)*')''', replacer, code)
    return masked, strings

def restore_strings(code: str, strings: dict) -> str:
    """
    Restore masked string literals by replacing placeholders with originals.
    Longer keys first to avoid partial overlaps.
    """
    for key in sorted(strings.keys(), key=len, reverse=True):
        code = code.replace(key, strings[key])
    return code

def split_code_and_comment(line: str):
    """
    Separate an R line into code and trailing comment.
    """
    parts = line.split("#", 1)
    if len(parts) == 1:
        return parts[0], ""
    return parts[0], "#" + parts[1]

# -----------------------------
# Preprocessing
# -----------------------------
def preprocess(r_code: str):
    """
    1) Mask strings
    2) Replace <- and -> with =
    3) Normalize variable names to snake_case (excluding comments)
    """
    masked, str_map = preserve_strings(r_code)
    # Replace assignment arrows
    masked = re.sub(r'(<-|->)', '=', masked)
    # Normalize names line by line
    lines = []
    for ln in masked.split("\n"):
        code_part, comment = split_code_and_comment(ln)
        if code_part.strip().startswith("#") or not code_part.strip():
            lines.append(ln)
        else:
            lines.append(to_snake_case(code_part) + comment)
    return "\n".join(lines), str_map

# -----------------------------
# Transform Functions
# -----------------------------
def transform_data_frame_creation(line: str) -> str:
    """
    df <- data.frame(a=..., b=..., c=...)
      → df = pd.DataFrame({"a":..., "b":..., "c":...})
    """
    m = re.match(r'(\w+)\s*=\s*data\.frame\s*\((.*)\)\s*$', line)
    if not m:
        return line
    var, body = m.group(1), m.group(2)
    # Split on top-level commas
    parts, buf, depth = [], "", 0
    for ch in body:
        if ch == '(':
            depth += 1
        elif ch == ')':
            depth -= 1
        if ch == ',' and depth == 0:
            parts.append(buf.strip())
            buf = ""
        else:
            buf += ch
    if buf.strip():
        parts.append(buf.strip())
    cols = []
    for part in parts:
        if "=" in part:
            k, v = part.split("=", 1)
            key = to_snake_case(k.strip())
            cols.append(f'"{key}": {v.strip()}')
    return f'{var} = pd.DataFrame({{{", ".join(cols)}}})'

def transform_logical_ops(line: str) -> str:
    # Replace R’s scalar && and || with Python and/or
    line = re.sub(r'&&', 'and', line)
    line = re.sub(r'\|\|', 'or', line)
    return line

def transform_numeric_slice(line: str) -> str:
    """
    df3[1:nrow(df), , drop=FALSE] → df3.iloc[:len(df), :]
    """
    line = re.sub(
        r'(\w+)\s*

\[\s*1\s*:\s*nrow\(\s*(\w+)\s*\)\s*,\s*,\s*drop\s*=\s*FALSE\s*\]

',
        r'\1.iloc[:len(\2), :]', line
    )
    return line

def transform_chained_null_drops(line: str) -> str:
    """
    df$col1 <- df$col2 <- NULL
      → df.drop(columns=["col1","col2"], inplace=True)
    """
    m = re.findall(r'(\w+)\$(\w+)\s*=', line)
    if m and line.strip().endswith("NULL"):
        dfname = m[0][0]
        cols = [to_snake_case(c) for _, c in m]
        cols_list = ", ".join(f'"{c}"' for c in cols)
        return f'{dfname}.drop(columns=[{cols_list}], inplace=True)'
    return line

def transform_new_column_assignment(line: str) -> str:
    # df$col = expr → df["col"] = expr
    return re.sub(
        r'(\w+)\$(\w+)\s*=\s*(.+)',
        lambda m: f'{m.group(1)}["{to_snake_case(m.group(2))}"] = {m.group(3).strip()}',
        line
    )

def transform_na_fill(line: str) -> str:
    """
    df$col[is.na(df$col)] = val
      → df.loc[df["col"].isna(), "col"] = val
    """
    return re.sub(
        r'(\w+)\$(\w+)\s*

\[\s*is\.na\(\1\$\2\)\s*\]

\s*=\s*(.+)',
        lambda m: f'{m.group(1)}.loc[{m.group(1)}["{m.group(2)}"].isna(), "{m.group(2)}"] = {m.group(3).strip()}',
        line
    )

def transform_ifelse(line: str) -> str:
    # ifelse(cond, yes, no) → np.where(cond, yes, no)
    return re.sub(
        r'ifelse\(\s*(.+?)\s*,\s*(.+?)\s*,\s*(.+?)\s*\)',
        r'np.where(\1, \2, \3)',
        line
    )

def transform_unique(line: str) -> str:
    # unique(df$col) → df["col"].unique()
    return re.sub(r'unique\(\s*(\w+)\$(\w+)\s*\)', r'\1["\2"].unique()', line)

def transform_element_assignment(line: str) -> str:
    # df$col[i] = val → df.loc[i-1, "col"] = val
    return re.sub(
        r'(\w+)\$(\w+)\s*

\[\s*(\w+)\s*\]

\s*=\s*(.+)',
        r'\1.loc[\3-1, "\2"] = \4',
        line
    )

def transform_functions(line: str) -> str:
    line = re.sub(r'(\w+)\s*=\s*function\s*\((.*?)\)', r'def \1(\2):', line)
    line = re.sub(r'return\((.*?)\)', r'return \1', line)
    line = re.sub(r'stop\((.*?)\)', r'raise Exception(\1)', line)
    return line

def transform_default_sysdate(line: str) -> str:
    # function(x = Sys.Date()) → def func(x=None):
    return re.sub(
        r'(\w+)\s*=\s*function\s*\(\s*(\w+)\s*=\s*Sys\.Date\(\)\s*\)',
        r'def \1(\2=None):',
        line
    )

def transform_s3_methods(line: str) -> str:
    # print.classname <- function(self) → class Classname: def __str__(self):
    m = re.match(r'print\.(\w+)\s*=\s*function\s*\(\s*self\s*\)', line)
    if m:
        cls = m.group(1).capitalize()
        return f'class {cls}:\n    def __str__(self):'
    return line

def transform_control(line: str) -> str:
    line = re.sub(r'^\s*if\s*\((.*?)\)\s*\{?$', r'if \1:', line)
    line = re.sub(r'^\s*else\s+if\s*\((.*?)\)\s*\{?$', r'elif \1:', line)
    line = re.sub(r'^\s*else\s*\{?$', r'else:', line)
    line = re.sub(r'for\s*\((\w+)\s+in\s+(\d+)\s*:\s*(\d+)\)', r'for \1 in range(\2, \3+1):', line)
    line = re.sub(r'while\s*\((.*?)\)\s*\{?$', r'while \1:', line)
    return line

def transform_vectors(line: str) -> str:
    line = re.sub(r'c\((.*?)\)', r'[\1]', line)
    line = re.sub(r'(\d+)\s*:\s*(\d+)', r'range(\1, \2+1)', line)
    def seq_repl(m):
        s, e, st = m.group(1), m.group(2), m.group(3)
        if st:
            return f'range({s}, {e}+1, {st})'
        return f'range({s}, {e}+1)'
    return re.sub(r'seq\(\s*(\d+)\s*,\s*(\d+)(?:\s*,\s*(\d+))?\)', seq_repl, line)

def transform_dataframe_access_and_names(line: str) -> str:
    line = re.sub(r'(\w+)\$(\w+)', r'\1["\2"]', line)
    line = re.sub(r'names\((\w+)\)\s*=\s*c\((.*?)\)', r'\1.columns = [\2]', line)
    line = re.sub(r'names\((\w+)\)', r'\1.columns.tolist()', line)
    return line

def transform_dataframe_subsetting(line: str) -> str:
    # subset(df, select=c(...))
    line = re.sub(r'subset\(\s*(\w+)\s*,\s*select\s*=\s*c\((.*?)\)\s*\)', r'\1[[\2]]', line)
    # df[, c(...)]
    line = re.sub(r'(\w+)\s*

\[\s*,\s*c\((.*?)\)\s*\]

', r'\1[[\2]]', line)
    # df[, var]
    line = re.sub(r'(\w+)\s*

\[\s*,\s*(\w+)\s*\]

', r'\1[\2]', line)
    # df[cond, c(...)]
    line = re.sub(r'(\w+)\s*

\[\s*(.*?)\s*,\s*c\((.*?)\)\s*\]

', r'\1.loc[\2, [\3]]', line)
    # df[cond, var]
    line = re.sub(r'(\w+)\s*

\[\s*(.*?)\s*,\s*(\w+)\s*\]

', r'\1.loc[\2, \3]', line)
    # df[cond, ]
    line = re.sub(r'(\w+)\s*

\[\s*(.*?)\s*,\s*\]

\s*', r'\1.loc[\2, :]', line)
    return line

def transform_dataframe_drops(line: str) -> str:
    return re.sub(
        r'(\w+)\$(\w+)\s*=\s*NULL',
        lambda m: f'{m.group(1)}.drop(columns=["{m.group(2)}"], inplace=True)',
        line
    )

def transform_dataframe_rbind_cbind(line: str) -> str:
    line = re.sub(r'rbind\((.*?)\)', r'pd.concat([\1], axis=0)', line)
    line = re.sub(r'cbind\((.*?)\)', r'pd.concat([\1], axis=1)', line)
    return line

def handle_merge(line: str) -> str:
    if "merge(" not in line:
        return line
    m = re.search(r'merge\(\s*(.*)\s*\)', line)
    if not m:
        return line
    body = m.group(1)
    # split on top-level commas
    parts, buf, depth = [], "", 0
    for ch in body:
        if ch in "([":
            depth += 1
        elif ch in ")]":
            depth -= 1
        if ch == "," and depth == 0:
            parts.append(buf.strip())
            buf = ""
        else:
            buf += ch
    if buf.strip():
        parts.append(buf.strip())
    left_df, right_df = parts[0], parts[1]
    how = "inner"
    on = []
    left_on = right_on = None
    for arg in parts[2:]:
        if "=" not in arg:
            continue
        k, v = [x.strip() for x in arg.split("=", 1)]
        if k == "all.x" and v in ("TRUE", "True"):
            how = "left"
        elif k == "all.y" and v in ("TRUE", "True"):
            how = "right"
        elif k == "all" and v in ("TRUE", "True"):
            how = "outer"
        elif k == "by":
            if v.startswith("c("):
                cols = re.findall(r'["\'](.*?)["\']', v)
                on = [to_snake_case(c) for c in cols]
            else:
                single = re.match(r'["\'](.+?)["\']', v).group(1)
                on = [to_snake_case(single)]
        elif k == "by.x":
            left_on = to_snake_case(re.match(r'["\'](.+?)["\']', v).group(1))
        elif k == "by.y":
            right_on = to_snake_case(re.match(r'["\'](.+?)["\']', v).group(1))
    # inline subsets already converted to .loc[...] earlier
    args = [left_df, right_df]
    kw = []
    if on:
        kw.append(f'on={[f\'"{c}"\' for c in on]}')
    if left_on and right_on:
        kw.append(f'left_on="{left_on}"')
        kw.append(f'right_on="{right_on}"')
    kw.append(f'how="{how}"')
    pandas_call = f'{left_df}.merge({right_df}, ' + ", ".join(kw) + ')'
    return line.replace(m.group(0), pandas_call)

def transform_sorting(line: str) -> str:
    line = re.sub(
        r'(\w+)\s*

\[\s*order\(\s*\1\$(\w+)\s*\)\s*,\s*\]

',
        r'\1.sort_values(by="\2")',
        line
    )
    line = re.sub(
        r'(\w+)\s*

\[\s*order\(\s*\1\$(\w+)\s*,\s*decreasing\s*=\s*TRUE\)\s*,\s*\]

',
        r'\1.sort_values(by="\2", ascending=False)',
        line
    )
    return line

def transform_subset(line: str) -> str:
    line = re.sub(r'subset\(\s*(\w+)\s*,\s*(.*?)\s*\)', r'\1[\2]', line)
    line = re.sub(r'is\.na\((.*?)\)', r'\1.isna()', line)
    line = re.sub(r'!\s*is\.na\((.*?)\)', r'\1.notna()', line)
    return line

def transform_membership(line: str) -> str:
    line = re.sub(r'(\w+)\s*%in%\s*c\((.*?)\)', r'\1.isin([\2])', line)
    line = re.sub(r'(\w+)\s*%ni%\s*c\((.*?)\)', r'~\1.isin([\2])', line)
    line = re.sub(r'(\w+)\s*%in%\s*

\[\s*(.*?)\s*\]

', r'\1 in [\2]', line)
    line = re.sub(r'(\w+)\s*%ni%\s*

\[\s*(.*?)\s*\]

', r'\1 not in [\2]', line)
    return line

def transform_df_counts_and_summary(line: str) -> str:
    line = re.sub(r'nrow\(\s*(\w+)\s*\)', r'len(\1)', line)
    line = re.sub(r'ncol\(\s*(\w+)\s*\)', r'len(\1.columns)', line)
    line = re.sub(r'dim\(\s*(\w+)\s*\)', r'\1.shape', line)
    line = re.sub(r'summary\(\s*(\w+)\s*\)', r'\1.describe()', line)
    return line

def transform_aggregation(line: str) -> str:
    line = re.sub(
        r'mean\(\s*(\w+)\$(\w+)\s*,\s*na\.rm\s*=\s*TRUE\)',
        r'\1["\2"].mean(skipna=True)', line
    )
    line = re.sub(
        r'sum\(\s*(\w+)\$(\w+)\s*,\s*na\.rm\s*=\s*TRUE\)',
        r'\1["\2"].sum(skipna=True)', line
    )
    return line

def transform_apply_family(line: str) -> str:
    line = re.sub(r'apply\(\s*(\w+)\s*,\s*1\s*,\s*(\w+)\)', r'\1.\2(axis=1)', line)
    line = re.sub(
        r'sapply\(\s*(\w+)\$(\w+)\s*,\s*(\w+)\)',
        r'\1["\2"].apply(\3)', line
    )
    line = re.sub(
        r'lapply\(\s*(\w+)\s*,\s*function\(\w+\)\s*(\w+)\$(\w+)\)',
        r'[\1_item["\3"] for \1_item in \1]',
        line
    )
    return line

def transform_io(line: str) -> str:
    line = re.sub(r'read\.csv\((.*?)\)', r'pd.read_csv(\1)', line)
    line = re.sub(r'write\.csv\(\s*(.*?),(.*?)\)', r'\2.to_csv(\1, index=False)', line)
    line = re.sub(
        r'list\.files\(\s*pattern\s*=\s*["\'](.*?)["\']\s*\)',
        r'glob.glob("\1")', line
    )
    line = re.sub(
        r'grep\("(.+?)"\s*,\s*(\w+)\)',
        r'[x for x in \2 if re.search("\1", x)]',
        line
    )
    return line

def transform_dates(line: str) -> str:
    line = re.sub(r'Sys\.Date\(\)', r'datetime.date.today()', line)
    line = re.sub(r'Sys\.time\(\)', r'datetime.datetime.now()', line)
    line = re.sub(
        r'Sys\.Date\(\)\s*-\s*(\d+)',
        r'datetime.date.today() - datetime.timedelta(days=\1)',
        line
    )
    return line

def transform_factor(line: str) -> str:
    return re.sub(r'factor\((.*?)\)', r'pd.Categorical(\1)', line)

def handle_pipe(line: str) -> str:
    if '%>%' not in line:
        return line
    parts = [p.strip() for p in line.split('%>%')]
    df = parts[0]
    out = []
    current = df
    group_key = None
    for step in parts[1:]:
        m = re.match(r'(\w+)\((.*)\)', step)
        if not m:
            continue
        op, args = m.group(1), m.group(2)
        if op == 'filter':
            out.append(f'{current} = {current}[{args}]')
        elif op == 'select':
            cols = args.replace('c(', '[').replace(')', ']')
            out.append(f'{current} = {current}[[{cols.strip("[]")}]]')
        elif op == 'mutate':
            assigns = [a.strip() for a in args.split(',')]
            for a in assigns:
                col, expr = a.split('=', 1)
                out.append(f'{current}["{col.strip()}"] = {expr.strip()}')
        elif op == 'arrange':
            cols = [c.strip() for c in args.split(',')]
            desc = [c[5:-1] for c in cols if c.startswith('desc(')]
            if desc:
                out.append(f'{current} = {current}.sort_values(by={desc}, ascending=False)')
            else:
                out.append(f'{current} = {current}.sort_values(by={[c for c in cols]})')
        elif op == 'group_by':
            group_key = args.strip()
        elif op in ('summarise', 'summarize'):
            out.append(
                f'{current} = {current}.groupby("{group_key}")'
                f'["{args.split("=")[1].strip(") ")}"].'
                f'{args.split("(")[0]}()'
                f'.reset_index(name="{args.split("=")[0].strip()}")'
            )
    return "\n".join(out) if out else line

# -----------------------------
# Indentation Manager
# -----------------------------
def indent_code(lines, indent_str="    "):
    indent_level = 0
    out = []
    dedent_keys = ("elif ", "else:", "except ", "finally:")
    for raw in lines:
        stripped = raw.lstrip()
        if any(stripped.startswith(k) for k in dedent_keys):
            indent_level = max(indent_level - 1, 0)
        out.append(indent_str * indent_level + stripped)
        if stripped.endswith(":"):
            indent_level += 1
    return out

# -----------------------------
# Conversion Pipeline
# -----------------------------
def convert_r_to_python(r_code: str) -> str:
    masked, str_map = preprocess(r_code)
    out_lines = []
    for raw in masked.split("\n"):
        code_part, comment = split_code_and_comment(raw)
        ln = code_part
        if not ln.strip():
            out_lines.append(raw)
            continue
        for fn in (
            transform_data_frame_creation,
            transform_logical_ops,
            transform_numeric_slice,
            transform_chained_null_drops,
            transform_new_column_assignment,
            transform_na_fill,
            transform_ifelse,
            transform_unique,
            transform_element_assignment,
            transform_functions,
            transform_default_sysdate,
            transform_s3_methods,
            transform_control,
            transform_vectors,
            transform_dataframe_access_and_names,
            transform_dataframe_subsetting,
            transform_dataframe_drops,
            transform_dataframe_rbind_cbind,
            handle_merge,
            transform_sorting,
            transform_subset,
            transform_membership,
            transform_df_counts_and_summary,
            transform_aggregation,
            transform_apply_family,
            transform_io,
            transform_dates,
            transform_factor,
            handle_pipe
        ):
            ln = fn(ln)
        out_lines.append(ln + (" " + comment if comment else ""))
    indented = indent_code(out_lines)
    joined = "\n".join(indented)
    restored = restore_strings(joined, str_map)
    imports = [
        "import pandas as pd",
        "import numpy as np",
        "import datetime",
        "import glob",
        "import os",
        "import re"
    ]
    return "\n".join(imports) + "\n\n" + restored

# -----------------------------
# CLI Entry Point
# -----------------------------
if __name__ == "__main__":
    import sys
    if len(sys.argv) != 3:
        print("Usage: python converter.py <input.R> <output.py>")
        sys.exit(1)
    inp, outp = sys.argv[1], sys.argv[2]
    with open(inp) as f:
        rtext = f.read()
    pytext = convert_r_to_python(rtext)
    with open(outp, "w") as f:
        f.write(pytext)
    print(f"✅ Conversion complete. Saved to {outp}")
